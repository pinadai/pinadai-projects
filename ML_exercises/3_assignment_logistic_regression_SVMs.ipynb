{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73eede3c",
   "metadata": {},
   "source": [
    "# Assignment 3: Logistic Regression and SVMs\n",
    "## Daisy Pinaroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2486bd",
   "metadata": {},
   "source": [
    "First, we will explore our data and prepare it for analysis through feature engineering techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1deafa1",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6d4951f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>Succeeded</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11/21/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10/13/2015</td>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10/9/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                   Route  Succeeded  \\\n",
       "0           0  11/27/2015  Disappointment Cleaver          0   \n",
       "1           1  11/21/2015  Disappointment Cleaver          0   \n",
       "2           2  10/15/2015  Disappointment Cleaver          0   \n",
       "3           3  10/13/2015           Little Tahoma          0   \n",
       "4           4   10/9/2015  Disappointment Cleaver          0   \n",
       "\n",
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \n",
       "0             27.839583           68.004167             88.496250  \n",
       "1              2.245833          117.549667             93.660417  \n",
       "2             17.163625          259.121375            138.387000  \n",
       "3             19.591167          279.779167            176.382667  \n",
       "4             65.138333          264.687500             27.791292  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "# Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "# Print a few columns using head() function\n",
    "mt_rainier_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f2ab6",
   "metadata": {},
   "source": [
    "Features to keep:\n",
    "* Route\n",
    "* Temperature AVG\n",
    "* Relative Humidity AVG\n",
    "* Wind Speed Daily AVG\n",
    "* Wind Direction AVG\n",
    "* Solare Radiation AVG\n",
    "\n",
    "\n",
    "* I'm not keeping \"Date\" because it caused problems with scaling later on. \n",
    "* \"Battery Voltage AVG\" also seems like a feature that won't help the user decide whether to hike on a given day. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af33ff2",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b29ba9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "mt_rainier_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e3c9d",
   "metadata": {},
   "source": [
    "We won't have to drop any duplicate rows because there aren't any in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26d2c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e170c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1895 entries, 0 to 1894\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             1895 non-null   int64  \n",
      " 1   Date                   1895 non-null   object \n",
      " 2   Route                  1895 non-null   object \n",
      " 3   Succeeded              1895 non-null   int64  \n",
      " 4   Battery Voltage AVG    1895 non-null   float64\n",
      " 5   Temperature AVG        1895 non-null   float64\n",
      " 6   Relative Humidity AVG  1895 non-null   float64\n",
      " 7   Wind Speed Daily AVG   1895 non-null   float64\n",
      " 8   Wind Direction AVG     1895 non-null   float64\n",
      " 9   Solare Radiation AVG   1895 non-null   float64\n",
      "dtypes: float64(6), int64(2), object(2)\n",
      "memory usage: 148.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the columns using info() function, also checking for completeness\n",
    "mt_rainier_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8dc1ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1895\n",
      "Columns: 10\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of rows and columns in the dataframe\n",
    "\n",
    "# Rows\n",
    "rows = len(mt_rainier_df.index)\n",
    "\n",
    "# Columns\n",
    "col = len(mt_rainier_df.axes[1])\n",
    "\n",
    "print('Rows:',rows)\n",
    "print('Columns:', col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff6b58",
   "metadata": {},
   "source": [
    "I've determined the number of rows and columns in the dataframe because I would like to see if this changes after feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae31fb",
   "metadata": {},
   "source": [
    "### Feature and Label Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "958ad529",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Route  Temperature AVG  Relative Humidity AVG  \\\n",
       "0  Disappointment Cleaver        26.321667              19.715000   \n",
       "1  Disappointment Cleaver        31.300000              21.690708   \n",
       "2  Disappointment Cleaver        46.447917              27.211250   \n",
       "3           Little Tahoma        40.979583              28.335708   \n",
       "4  Disappointment Cleaver        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \n",
       "0             27.839583           68.004167             88.496250  \n",
       "1              2.245833          117.549667             93.660417  \n",
       "2             17.163625          259.121375            138.387000  \n",
       "3             19.591167          279.779167            176.382667  \n",
       "4             65.138333          264.687500             27.791292  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_rainier_features_df = mt_rainier_df[[\"Route\",\"Temperature AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\", \"Wind Direction AVG\",\"Solare Radiation AVG\"]] \n",
    "mt_rainier_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eec9e8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Succeeded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Succeeded\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "mt_rainier_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e07e9",
   "metadata": {},
   "source": [
    "Because \"Succeeded\" is classified as 0 and 1, that will be our label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21288fec",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "56b610a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature AVG  Relative Humidity AVG  Wind Speed Daily AVG  \\\n",
       "0        26.321667              19.715000             27.839583   \n",
       "1        31.300000              21.690708              2.245833   \n",
       "2        46.447917              27.211250             17.163625   \n",
       "3        40.979583              28.335708             19.591167   \n",
       "4        38.260417              74.329167             65.138333   \n",
       "\n",
       "   Wind Direction AVG  Solare Radiation AVG    0    1    2    3    4  ...  \\\n",
       "0           68.004167             88.496250  0.0  1.0  0.0  0.0  0.0  ...   \n",
       "1          117.549667             93.660417  0.0  1.0  0.0  0.0  0.0  ...   \n",
       "2          259.121375            138.387000  0.0  1.0  0.0  0.0  0.0  ...   \n",
       "3          279.779167            176.382667  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4          264.687500             27.791292  0.0  1.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "    12   13   14   15   16   17   18   19   20   21  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming categorical features into 1-hot\n",
    "route_names_to_list = mt_rainier_features_df[\"Route\"].to_list()\n",
    "\n",
    "# Converting the 1-dimensional list into a list of lists(2D)\n",
    "route_names_to_list_of_lists = []\n",
    "\n",
    "for route in route_names_to_list:\n",
    "    route_names_to_list_of_lists.append([route])\n",
    "\n",
    "# Defining an object\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit our data (i.e., extract and order vocabulary)\n",
    "route_encoder.fit(route_names_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "# Now transform each example in our data into 1-hot form\n",
    "route_names_transformed = route_encoder.transform(route_names_to_list_of_lists)\n",
    "\n",
    "# Transform the result object into a matrix\n",
    "route_names_transformed = route_names_transformed.toarray()\n",
    "print(route_names_transformed)\n",
    "\n",
    "# Create a dataframe back from the array\n",
    "route_names_transformed_df = pd.DataFrame(route_names_transformed)\n",
    "\n",
    "# Now concatenate this feature back to the original dataframe \n",
    "mt_rainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_names_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mt_rainier_features_transformed_df = pd.concat([mt_rainier_features_df,route_names_transformed_df], axis=1)\n",
    "\n",
    "# We don't need Route now since we have already transformed it\n",
    "mt_rainier_features_transformed_df = mt_rainier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "mt_rainier_features_transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196ae7f",
   "metadata": {},
   "source": [
    "The only categorical feature we have is \"Route\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9371ea70",
   "metadata": {},
   "source": [
    "Now that we have transformed the only categorical variable, we are left with numerical variables. We'll scale these features using Standard scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2dedc",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "118bdbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.580891</td>\n",
       "      <td>-1.269311</td>\n",
       "      <td>1.895222</td>\n",
       "      <td>-0.958813</td>\n",
       "      <td>-1.567664</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.065112</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.045992</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.115624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.033951</td>\n",
       "      <td>-1.180109</td>\n",
       "      <td>-0.902775</td>\n",
       "      <td>-0.414849</td>\n",
       "      <td>-1.520897</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.065112</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.045992</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.115624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.630261</td>\n",
       "      <td>-0.930861</td>\n",
       "      <td>0.728090</td>\n",
       "      <td>1.139477</td>\n",
       "      <td>-1.115850</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.065112</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.045992</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.115624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029488</td>\n",
       "      <td>-0.880092</td>\n",
       "      <td>0.993477</td>\n",
       "      <td>1.366280</td>\n",
       "      <td>-0.771758</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-1.467337</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.065112</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.045992</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.115624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.269251</td>\n",
       "      <td>1.196481</td>\n",
       "      <td>5.972851</td>\n",
       "      <td>1.200588</td>\n",
       "      <td>-2.117412</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.065112</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.045992</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-0.115624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature AVG  Relative Humidity AVG  Wind Speed Daily AVG  \\\n",
       "0        -1.580891              -1.269311              1.895222   \n",
       "1        -1.033951              -1.180109             -0.902775   \n",
       "2         0.630261              -0.930861              0.728090   \n",
       "3         0.029488              -0.880092              0.993477   \n",
       "4        -0.269251               1.196481              5.972851   \n",
       "\n",
       "   Wind Direction AVG  Solare Radiation AVG         0         1         2  \\\n",
       "0           -0.958813             -1.567664 -0.032504  0.681507 -0.429389   \n",
       "1           -0.414849             -1.520897 -0.032504  0.681507 -0.429389   \n",
       "2            1.139477             -1.115850 -0.032504  0.681507 -0.429389   \n",
       "3            1.366280             -0.771758 -0.032504 -1.467337 -0.429389   \n",
       "4            1.200588             -2.117412 -0.032504  0.681507 -0.429389   \n",
       "\n",
       "          3         4  ...       12        13        14        15        16  \\\n",
       "0 -0.051434 -0.120225  ... -0.03982 -0.032504 -0.065112 -0.032504 -0.022978   \n",
       "1 -0.051434 -0.120225  ... -0.03982 -0.032504 -0.065112 -0.032504 -0.022978   \n",
       "2 -0.051434 -0.120225  ... -0.03982 -0.032504 -0.065112 -0.032504 -0.022978   \n",
       "3 -0.051434 -0.120225  ... -0.03982 -0.032504 -0.065112 -0.032504 -0.022978   \n",
       "4 -0.051434 -0.120225  ... -0.03982 -0.032504 -0.065112 -0.032504 -0.022978   \n",
       "\n",
       "         17        18        19        20        21  \n",
       "0 -0.022978 -0.045992 -0.022978 -0.032504 -0.115624  \n",
       "1 -0.022978 -0.045992 -0.022978 -0.032504 -0.115624  \n",
       "2 -0.022978 -0.045992 -0.022978 -0.032504 -0.115624  \n",
       "3 -0.022978 -0.045992 -0.022978 -0.032504 -0.115624  \n",
       "4 -0.022978 -0.045992 -0.022978 -0.032504 -0.115624  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_transformed_df.columns\n",
    "\n",
    "mt_rainier_features_transformed_df[all_columns] = scaler.fit_transform(mt_rainier_features_transformed_df[all_columns])\n",
    "mt_rainier_features_transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b955790",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "efa08fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 27), (341, 1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_transformed_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5eb138",
   "metadata": {},
   "source": [
    "## Defining and training Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4b49b",
   "metadata": {},
   "source": [
    "We'll use four model candidates:\n",
    "* Logistic Regression with no regularization (default)\n",
    "* Logistic Regression with L2 regularization\n",
    "* Support Vector Classifier with Linear Kernel\n",
    "* Support Vector Classifier with Polynomial Kernel (Degree = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9586d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae1a10",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation\n",
    "For each fold we train every model, evaluate their accuracies on training and validation data and selsct the model that offers the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4a547b2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lr_vanilla ...\n",
      "Average training accuracy for model lr_vanilla = 0.6277126099706745\n",
      "Average validation accuracy for model lr_vanilla = 0.612316715542522\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n",
      "Average training accuracy for model lr_L2 = 0.6275659824046921\n",
      "Average validation accuracy for model lr_L2 = 0.6129032258064516\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.6174486803519061\n",
      "Average validation accuracy for model svm_linear = 0.6070381231671554\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.6117302052785923\n",
      "Average validation accuracy for model svm_poly = 0.5829912023460411\n",
      "-----------------------------------\n",
      "Best model for the task is lr_L2 which offers the validation accuracy of 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5cf30",
   "metadata": {},
   "source": [
    "## Insights \n",
    "All models are operating equally badly and are underfitting. The ideal training accuracy should be more than 0.9 (>90% of the examples in training data should be classified correctly). \n",
    "\n",
    "In such cases we can try to improve data and extract better features such as trail conditions (i.e. rocky, muddy, slippery, etc.), potential hazards, difficulty level of trail, and wildlife presence. Although these features aren't present in our current dataframe, I think they could improve user experience over time and help increase accuracy. Another way users' experience could be improved is collecting data over a longer span of time, rather than 1 year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9d7e2",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "Find out the best set of features and the best model by **trying many possible combination of features**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5959fb",
   "metadata": {},
   "source": [
    "Same features as previous model, but **WITHOUT ROUTE**\n",
    "## MODEL 2\n",
    "Features:\n",
    "* Temperature AVG\n",
    "* Relative Humidity AVG\n",
    "* Wind Speed Daily AVG\n",
    "* Wind Direction AVG\n",
    "* Solare Radiation AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33b2217c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 training data shape = ((1364, 5), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 5), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 5), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 5), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 5), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 5), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 5), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 5), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 5), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 5), (341, 1))\n",
      "Evaluating lr_vanilla ...\n",
      "Average training accuracy for model lr_vanilla = 0.6227272727272727\n",
      "Average validation accuracy for model lr_vanilla = 0.6041055718475073\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n",
      "Average training accuracy for model lr_L2 = 0.6227272727272727\n",
      "Average validation accuracy for model lr_L2 = 0.6041055718475073\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\AppData\\Local\\Temp\\ipykernel_10680\\3950465780.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mt_rainier_features_df[all_columns] = scaler.fit_transform(mt_rainier_features_df[all_columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model svm_linear = 0.6087976539589443\n",
      "Average validation accuracy for model svm_linear = 0.6064516129032258\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.5942815249266863\n",
      "Average validation accuracy for model svm_poly = 0.5894428152492669\n",
      "-----------------------------------\n",
      "Best model for the task is svm_linear which offers the validation accuracy of 0.6064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "#Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "mt_rainier_df = mt_rainier_df.drop_duplicates()\n",
    "\n",
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()\n",
    "\n",
    "# Defining our features\n",
    "mt_rainier_features_df = mt_rainier_df[[\"Temperature AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\", \"Wind Direction AVG\",\"Solare Radiation AVG\"]] \n",
    "\n",
    "# Defining our labels\n",
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "\n",
    "# Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_df.columns\n",
    "\n",
    "mt_rainier_features_df[all_columns] = scaler.fit_transform(mt_rainier_features_df[all_columns])\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}\n",
    "\n",
    "# K-fold cross validation\n",
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466d927",
   "metadata": {},
   "source": [
    "## MODEL 3\n",
    "Features:\n",
    "* Route\n",
    "* Battery Voltage AVG\n",
    "* Temperature AVG\n",
    "* Relative Humidity AVG\n",
    "* Wind Speed Daily AVG\n",
    "* Wind Direction AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d27c0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "Fold 1 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 27), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 27), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 27), (341, 1))\n",
      "Evaluating lr_vanilla ...\n",
      "Average training accuracy for model lr_vanilla = 0.6043988269794721\n",
      "Average validation accuracy for model lr_vanilla = 0.5935483870967742\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model lr_L2 = 0.6043988269794721\n",
      "Average validation accuracy for model lr_L2 = 0.5935483870967742\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.58841642228739\n",
      "Average validation accuracy for model svm_linear = 0.5747800586510264\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.5998533724340176\n",
      "Average validation accuracy for model svm_poly = 0.5782991202346042\n",
      "-----------------------------------\n",
      "Best model for the task is lr_vanilla which offers the validation accuracy of 0.5935483870967742\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "#Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "mt_rainier_df = mt_rainier_df.drop_duplicates()\n",
    "\n",
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()\n",
    "\n",
    "\n",
    "# Defining our features\n",
    "mt_rainier_features_df = mt_rainier_df[[\"Route\", \"Battery Voltage AVG\", \"Temperature AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\", \"Wind Direction AVG\"]] \n",
    "\n",
    "# Defining our labels\n",
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "\n",
    "\n",
    "# Transforming categorical features (Route) into 1-hot\n",
    "route_names_to_list = mt_rainier_features_df[\"Route\"].to_list()\n",
    "\n",
    "# Converting the 1-dimensional list into a list of lists(2D)\n",
    "route_names_to_list_of_lists = []\n",
    "\n",
    "for route in route_names_to_list:\n",
    "    route_names_to_list_of_lists.append([route])\n",
    "\n",
    "# Defining an object\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit our data (i.e., extract and order vocabulary)\n",
    "route_encoder.fit(route_names_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "# Now transform each example in our data into 1-hot form\n",
    "route_names_transformed = route_encoder.transform(route_names_to_list_of_lists)\n",
    "\n",
    "# Transform the result object into a matrix\n",
    "route_names_transformed = route_names_transformed.toarray()\n",
    "print(route_names_transformed)\n",
    "\n",
    "# Create a dataframe back from the array\n",
    "route_names_transformed_df = pd.DataFrame(route_names_transformed)\n",
    "\n",
    "# Now concatenate this feature back to the original dataframe \n",
    "mt_rainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_names_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mt_rainier_features_transformed_df = pd.concat([mt_rainier_features_df,route_names_transformed_df], axis=1)\n",
    "\n",
    "# We don't need Route now since we have already transformed it\n",
    "mt_rainier_features_transformed_df = mt_rainier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "mt_rainier_features_transformed_df.head()\n",
    "\n",
    "\n",
    "# Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_transformed_df.columns\n",
    "\n",
    "mt_rainier_features_transformed_df[all_columns] = scaler.fit_transform(mt_rainier_features_transformed_df[all_columns])\n",
    "\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_transformed_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}\n",
    "\n",
    "# K-fold cross validation\n",
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02cefc",
   "metadata": {},
   "source": [
    "## MODEL 4\n",
    "Features:\n",
    "* Route\n",
    "* Temperature AVG\n",
    "* Relative Humidity AVG\n",
    "* Wind Speed Daily AVG\n",
    "* Solare Radiation AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4cbb1bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "Fold 1 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 26), (341, 1))\n",
      "Evaluating lr_vanilla ...\n",
      "Average training accuracy for model lr_vanilla = 0.6221407624633432\n",
      "Average validation accuracy for model lr_vanilla = 0.6129032258064516\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model lr_L2 = 0.6230205278592376\n",
      "Average validation accuracy for model lr_L2 = 0.612316715542522\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.6171554252199414\n",
      "Average validation accuracy for model svm_linear = 0.6082111436950146\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.6089442815249267\n",
      "Average validation accuracy for model svm_poly = 0.580058651026393\n",
      "-----------------------------------\n",
      "Best model for the task is lr_vanilla which offers the validation accuracy of 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "#Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "mt_rainier_df = mt_rainier_df.drop_duplicates()\n",
    "\n",
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()\n",
    "\n",
    "\n",
    "# Defining our features\n",
    "mt_rainier_features_df = mt_rainier_df[[\"Route\", \"Temperature AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\", \"Solare Radiation AVG\"]] \n",
    "\n",
    "# Defining our labels\n",
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "\n",
    "\n",
    "# Transforming categorical features (Route) into 1-hot\n",
    "route_names_to_list = mt_rainier_features_df[\"Route\"].to_list()\n",
    "\n",
    "# Converting the 1-dimensional list into a list of lists(2D)\n",
    "route_names_to_list_of_lists = []\n",
    "\n",
    "for route in route_names_to_list:\n",
    "    route_names_to_list_of_lists.append([route])\n",
    "\n",
    "# Defining an object\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit our data (i.e., extract and order vocabulary)\n",
    "route_encoder.fit(route_names_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "# Now transform each example in our data into 1-hot form\n",
    "route_names_transformed = route_encoder.transform(route_names_to_list_of_lists)\n",
    "\n",
    "# Transform the result object into a matrix\n",
    "route_names_transformed = route_names_transformed.toarray()\n",
    "print(route_names_transformed)\n",
    "\n",
    "# Create a dataframe back from the array\n",
    "route_names_transformed_df = pd.DataFrame(route_names_transformed)\n",
    "\n",
    "# Now concatenate this feature back to the original dataframe \n",
    "mt_rainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_names_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mt_rainier_features_transformed_df = pd.concat([mt_rainier_features_df,route_names_transformed_df], axis=1)\n",
    "\n",
    "# We don't need Route now since we have already transformed it\n",
    "mt_rainier_features_transformed_df = mt_rainier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "\n",
    "\n",
    "# Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_transformed_df.columns\n",
    "\n",
    "mt_rainier_features_transformed_df[all_columns] = scaler.fit_transform(mt_rainier_features_transformed_df[all_columns])\n",
    "\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_transformed_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}\n",
    "\n",
    "# K-fold cross validation\n",
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62363082",
   "metadata": {},
   "source": [
    "## MODEL 5\n",
    "Features:\n",
    "* Route\n",
    "* Battery Voltage AVG\n",
    "* Wind Speed Daily AVG\n",
    "* Wind Direction AVG \n",
    "* Solare Radiation AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e5c5cfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "Fold 1 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 26), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 26), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 26), (341, 1))\n",
      "Evaluating lr_vanilla ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model lr_vanilla = 0.6387096774193548\n",
      "Average validation accuracy for model lr_vanilla = 0.6228739002932551\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n",
      "Average training accuracy for model lr_L2 = 0.6387096774193548\n",
      "Average validation accuracy for model lr_L2 = 0.6228739002932551\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.6177419354838709\n",
      "Average validation accuracy for model svm_linear = 0.6111436950146627\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.6095307917888563\n",
      "Average validation accuracy for model svm_poly = 0.5835777126099707\n",
      "-----------------------------------\n",
      "Best model for the task is lr_vanilla which offers the validation accuracy of 0.6228739002932551\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "#Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "# Dropping duplicates, if any\n",
    "mt_rainier_df = mt_rainier_df.drop_duplicates()\n",
    "\n",
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()\n",
    "\n",
    "\n",
    "# Defining our features\n",
    "mt_rainier_features_df = mt_rainier_df[[\"Route\", \"Battery Voltage AVG\",\"Wind Speed Daily AVG\", \"Wind Direction AVG\", \"Solare Radiation AVG\"]] \n",
    "\n",
    "# Defining our labels\n",
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "\n",
    "\n",
    "# Transforming categorical features (Route) into 1-hot\n",
    "route_names_to_list = mt_rainier_features_df[\"Route\"].to_list()\n",
    "\n",
    "# Converting the 1-dimensional list into a list of lists(2D)\n",
    "route_names_to_list_of_lists = []\n",
    "\n",
    "for route in route_names_to_list:\n",
    "    route_names_to_list_of_lists.append([route])\n",
    "\n",
    "# Defining an object\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit our data (i.e., extract and order vocabulary)\n",
    "route_encoder.fit(route_names_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "# Now transform each example in our data into 1-hot form\n",
    "route_names_transformed = route_encoder.transform(route_names_to_list_of_lists)\n",
    "\n",
    "# Transform the result object into a matrix\n",
    "route_names_transformed = route_names_transformed.toarray()\n",
    "print(route_names_transformed)\n",
    "\n",
    "# Create a dataframe back from the array\n",
    "route_names_transformed_df = pd.DataFrame(route_names_transformed)\n",
    "\n",
    "# Now concatenate this feature back to the original dataframe \n",
    "mt_rainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_names_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mt_rainier_features_transformed_df = pd.concat([mt_rainier_features_df,route_names_transformed_df], axis=1)\n",
    "\n",
    "# We don't need Route now since we have already transformed it\n",
    "mt_rainier_features_transformed_df = mt_rainier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "\n",
    "\n",
    "# Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_transformed_df.columns\n",
    "\n",
    "mt_rainier_features_transformed_df[all_columns] = scaler.fit_transform(mt_rainier_features_transformed_df[all_columns])\n",
    "\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_transformed_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}\n",
    "\n",
    "# K-fold cross validation\n",
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11c62b",
   "metadata": {},
   "source": [
    "## MODEL 6\n",
    "Features:\n",
    "* Route\n",
    "* Wind Speed Daily AVG\n",
    "* Solare Radiation AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "498fb322",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "Fold 1 training data shape = ((1364, 24), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 24), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 24), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 24), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 24), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 24), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 24), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 24), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 24), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 24), (341, 1))\n",
      "Evaluating lr_vanilla ...\n",
      "Average training accuracy for model lr_vanilla = 0.6234604105571847\n",
      "Average validation accuracy for model lr_vanilla = 0.612316715542522\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model lr_L2 = 0.6234604105571847\n",
      "Average validation accuracy for model lr_L2 = 0.612316715542522\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.6195014662756598\n",
      "Average validation accuracy for model svm_linear = 0.6134897360703813\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.5972140762463344\n",
      "Average validation accuracy for model svm_poly = 0.5759530791788856\n",
      "-----------------------------------\n",
      "Best model for the task is svm_linear which offers the validation accuracy of 0.6134897360703813\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "#Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "# Dropping duplicates, if any\n",
    "mt_rainier_df = mt_rainier_df.drop_duplicates()\n",
    "\n",
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()\n",
    "\n",
    "\n",
    "# Defining our features\n",
    "mt_rainier_features_df = mt_rainier_df[[\"Route\",\"Wind Speed Daily AVG\", \"Solare Radiation AVG\"]] \n",
    "\n",
    "# Defining our labels\n",
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "\n",
    "\n",
    "# Transforming categorical features (Route) into 1-hot\n",
    "route_names_to_list = mt_rainier_features_df[\"Route\"].to_list()\n",
    "\n",
    "# Converting the 1-dimensional list into a list of lists(2D)\n",
    "route_names_to_list_of_lists = []\n",
    "\n",
    "for route in route_names_to_list:\n",
    "    route_names_to_list_of_lists.append([route])\n",
    "\n",
    "# Defining an object\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit our data (i.e., extract and order vocabulary)\n",
    "route_encoder.fit(route_names_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "# Now transform each example in our data into 1-hot form\n",
    "route_names_transformed = route_encoder.transform(route_names_to_list_of_lists)\n",
    "\n",
    "# Transform the result object into a matrix\n",
    "route_names_transformed = route_names_transformed.toarray()\n",
    "print(route_names_transformed)\n",
    "\n",
    "# Create a dataframe back from the array\n",
    "route_names_transformed_df = pd.DataFrame(route_names_transformed)\n",
    "\n",
    "# Now concatenate this feature back to the original dataframe \n",
    "mt_rainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_names_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mt_rainier_features_transformed_df = pd.concat([mt_rainier_features_df,route_names_transformed_df], axis=1)\n",
    "\n",
    "# We don't need Route now since we have already transformed it\n",
    "mt_rainier_features_transformed_df = mt_rainier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "\n",
    "\n",
    "# Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_transformed_df.columns\n",
    "\n",
    "mt_rainier_features_transformed_df[all_columns] = scaler.fit_transform(mt_rainier_features_transformed_df[all_columns])\n",
    "\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_transformed_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}\n",
    "\n",
    "# K-fold cross validation\n",
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a44b7",
   "metadata": {},
   "source": [
    "## MODEL 7\n",
    "Features:\n",
    "* Route\n",
    "* Battery Voltage\n",
    "* Wind Speed Daily AVG\n",
    "* Solare Radiation AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ce06139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 training data shape = ((1364, 25), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 25), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 25), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 25), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 25), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 25), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 25), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 25), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 25), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 25), (341, 1))\n",
      "Evaluating lr_vanilla ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daisy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training accuracy for model lr_vanilla = 0.6372434017595308\n",
      "Average validation accuracy for model lr_vanilla = 0.6287390029325512\n",
      "-----------------------------------\n",
      "Evaluating lr_L2 ...\n",
      "Average training accuracy for model lr_L2 = 0.6370967741935483\n",
      "Average validation accuracy for model lr_L2 = 0.6281524926686217\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.6165689149560117\n",
      "Average validation accuracy for model svm_linear = 0.612316715542522\n",
      "-----------------------------------\n",
      "Evaluating svm_poly ...\n",
      "Average training accuracy for model svm_poly = 0.6070381231671556\n",
      "Average validation accuracy for model svm_poly = 0.5777126099706745\n",
      "-----------------------------------\n",
      "Best model for the task is lr_vanilla which offers the validation accuracy of 0.6287390029325512\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset as a dataframe using pandas library \n",
    "import pandas as pd\n",
    "#Importing OneHotEncoder class from scikit-learn preprocessing for later use\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mt_rainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "\n",
    "# Dropping duplicates, if any\n",
    "mt_rainier_df = mt_rainier_df.drop_duplicates()\n",
    "\n",
    "# Applying dropna() for completeness\n",
    "mt_rainier_df = mt_rainier_df.dropna()\n",
    "\n",
    "\n",
    "# Defining our features\n",
    "mt_rainier_features_df = mt_rainier_df[[\"Route\",\"Battery Voltage AVG\",\"Wind Speed Daily AVG\", \"Solare Radiation AVG\"]] \n",
    "\n",
    "# Defining our labels\n",
    "mt_rainier_labels_df = mt_rainier_df[[\"Succeeded\"]]\n",
    "\n",
    "\n",
    "# Transforming categorical features (Route) into 1-hot\n",
    "route_names_to_list = mt_rainier_features_df[\"Route\"].to_list()\n",
    "\n",
    "# Converting the 1-dimensional list into a list of lists(2D)\n",
    "route_names_to_list_of_lists = []\n",
    "\n",
    "for route in route_names_to_list:\n",
    "    route_names_to_list_of_lists.append([route])\n",
    "\n",
    "# Defining an object\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit our data (i.e., extract and order vocabulary)\n",
    "route_encoder.fit(route_names_to_list_of_lists)\n",
    "\n",
    "# Now transform each example in our data into 1-hot form\n",
    "route_names_transformed = route_encoder.transform(route_names_to_list_of_lists)\n",
    "\n",
    "# Transform the result object into a matrix\n",
    "route_names_transformed = route_names_transformed.toarray()\n",
    "\n",
    "# Create a dataframe back from the array\n",
    "route_names_transformed_df = pd.DataFrame(route_names_transformed)\n",
    "\n",
    "# Now concatenate this feature back to the original dataframe \n",
    "mt_rainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_names_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mt_rainier_features_transformed_df = pd.concat([mt_rainier_features_df,route_names_transformed_df], axis=1)\n",
    "\n",
    "# We don't need Route now since we have already transformed it\n",
    "mt_rainier_features_transformed_df = mt_rainier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "\n",
    "\n",
    "# Scaling our features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = mt_rainier_features_transformed_df.columns\n",
    "\n",
    "mt_rainier_features_transformed_df[all_columns] = scaler.fit_transform(mt_rainier_features_transformed_df[all_columns])\n",
    "\n",
    "\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = mt_rainier_features_transformed_df.to_numpy()\n",
    "labels = mt_rainier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = [] # this is an inefficient way but still do it\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "# Now let's define our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LR with no regularizer\n",
    "lr_vanilla = LogisticRegression(penalty=\"none\")\n",
    "\n",
    "# LR with regularizer\n",
    "lr_L2 = LogisticRegression(penalty=\"l2\")\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "\n",
    "# SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel=\"poly\",degree=2)\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              \"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "              \"svm_poly\":svm_poly}\n",
    "\n",
    "# K-fold cross validation\n",
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Let's store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b13fe",
   "metadata": {},
   "source": [
    "### Summary (ranked from best to worst):\n",
    "1. Model 7- lr_vanilla: 0.62874\n",
    "2. Model 5- lr_vanilla: 0.62287\n",
    "3. Model 6- svm_linear: 0.61349\n",
    "4. Original- lr_L2: 0.61290\n",
    "5. Model 4- lr_vanilla: 0.61290\n",
    "6. Model 2- svm_linear: 0.60645\n",
    "7. Model 3- lr_vanilla: 0.59355"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f806cd",
   "metadata": {},
   "source": [
    "## Which was the best model?\n",
    "I found that the best model was Model 7, which was logistic regression with no regularization (lr_vanilla) producing a validation accuracy of 0.629. \n",
    "\n",
    "The best features were:\n",
    "* Route\n",
    "* Battery Voltage AVG\n",
    "* Wind Speed Daily AVG\n",
    "* Solare Radiation AVG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915b062",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* Original model & Model 4 produced the same validation accuracy. Model 4 did not include \"Wind Direction AVG\". I find this interesting. Maybe \"Wind Direction AVG\" is not as impactful compared to the other features.\n",
    "* I was shocked to see that \"Battery Voltage AVG\" was more impactful than I thought. I wonder why that is.\n",
    "* *I was a bit confused on when to use MinMaxScaling vs. StandardScaling. I just decided to use StandardScaling because of the lab, however I noticed how it scaled the one-hot encodings so I wasn't 100% sure if it was the right scaler to use.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

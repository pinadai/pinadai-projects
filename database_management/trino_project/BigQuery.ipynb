{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec6a454-c8bf-4952-8f24-13bb933a14e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final Project Milestone 1\n",
    "# Part 4: BigQuery\n",
    "## Daisy Pinaroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0237a4-a860-4997-836b-a10d2f3ed290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = \"XXXX\"\n",
    "DATASET = \"XXXX\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9e17f0-07a2-42a0-9dda-59103a1d5bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'cs327e_final_project_2023' created successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "### Creating final_project dataset\n",
    "client = bigquery.Client(project=PROJECT, location=REGION)\n",
    "\n",
    "# Create dataset reference\n",
    "final_proj_dataset_ref = client.dataset(DATASET)\n",
    "\n",
    "final_proj_dataset = bigquery.Dataset(final_proj_dataset_ref)\n",
    "final_proj_dataset.location = REGION\n",
    "\n",
    "# create dataset\n",
    "try:\n",
    "    client.create_dataset(final_proj_dataset, exists_ok=True)\n",
    "    print(f\"Dataset '{DATASET}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while creating dataset '{DATASET}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2ac212-6047-4abd-ab96-1baece6c90c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into cs327e_final_project_2023.\n"
     ]
    }
   ],
   "source": [
    "### Importing reservations_data_postgresql.csv and ticketing_data_mongodb.csv as tables in the database\n",
    "### postgres.reservations.cnt_code must exist in bigquery.currency.cnt_code\n",
    "### mongodb.ticketing.curr_code must exist in bigquery.currency.curr_code\n",
    "\n",
    "# Loading reservations_data_postgresql.csv\n",
    "from google.cloud import bigquery\n",
    "\n",
    "try:\n",
    "    client = bigquery.Client(project=PROJECT, location=REGION)\n",
    "\n",
    "    # Specify references\n",
    "    dataset_ref = client.dataset(DATASET)\n",
    "    table_ref = dataset_ref.table(\"reservations\")\n",
    "\n",
    "    # GCS path to the CSV file\n",
    "    gcs_path = 'gs://XXXX'\n",
    "\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"res_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"cust_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"prp_nm\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"prp_ch\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"adr_line_1\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"adr_line_2\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"city\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"state\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"postal_cd\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"lat\", \"NUMERIC\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"long\", \"NUMERIC\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"cnt_code\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"arr_date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"dep_date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"pmt_amt\", \"NUMERIC\", mode=\"REQUIRED\"),\n",
    "    ]\n",
    "\n",
    "    # Load data from GCS into BigQuery with the specified schema\n",
    "    job_config = bigquery.LoadJobConfig(schema=schema, skip_leading_rows=1)\n",
    "    job = client.load_table_from_uri(gcs_path, table_ref, job_config=job_config)\n",
    "\n",
    "    # Wait for the job to complete\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Data loaded successfully into {DATASET}.\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while loading reservations data:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab5fdd14-ecb6-4d6f-977a-fa35cfecd5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\n",
      "DEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/112246414225-compute@developer.gserviceaccount.com/token?scopes=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into cs327e_final_project_2023 for table ticketing.\n"
     ]
    }
   ],
   "source": [
    "# Loading ticketing_data_mongodb.csv\n",
    "from google.cloud import bigquery\n",
    "\n",
    "TABLE = \"ticketing\"\n",
    "\n",
    "try:\n",
    "    client = bigquery.Client(project=PROJECT, location=REGION)\n",
    "\n",
    "    # Specify references\n",
    "    dataset_ref = client.dataset(DATASET)\n",
    "    table_ref = dataset_ref.table(TABLE)\n",
    "\n",
    "    # GCS path to the CSV file\n",
    "    gcs_path = 'gs://XXXX'\n",
    "\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"tck_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"cust_id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"airline\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"flight_nm\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"dep_airport\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"arr_airport\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"dep_date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"dep_time\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"arr_date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"arr_time\", \"DATETIME\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"stops\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"tik_amt\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"curr_code\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    ]\n",
    "    \n",
    "    # Load data from GCS into BigQuery with the specified schema\n",
    "    job_config = bigquery.LoadJobConfig(schema=schema, skip_leading_rows=1)\n",
    "    job = client.load_table_from_uri(gcs_path, table_ref, job_config=job_config)\n",
    "    \n",
    "    # Wait for the job to complete\n",
    "    job.result()\n",
    "\n",
    "    print(f\"Data loaded successfully into {DATASET} for table {TABLE}.\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while loading ticketing data:\", e)\n",
    "    \n",
    "    '''\n",
    "    # Print detailed error information\n",
    "    if hasattr(job, 'errors') and job.errors:\n",
    "        for error in job.errors:\n",
    "            logging.error(f\"Error message: {error['message']}\")\n",
    "            logging.error(f\"Reason: {error.get('reason', 'N/A')}\")\n",
    "    else:\n",
    "        logging.error(\"No detailed error information available.\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9579827c-3f79-4af4-bd05-f3362486123b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data cleared from currency in cs327e_final_project_2023.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from google.cloud import bigquery\n",
    "\n",
    "### Creating final_project dataset\n",
    "client = bigquery.Client(project=PROJECT, location=REGION)\n",
    "\n",
    "TABLE = \"currency\"\n",
    "table_ref = client.dataset(DATASET).table(TABLE)\n",
    "delete_query = f\"DELETE FROM `{PROJECT}.{DATASET}.{TABLE}` WHERE TRUE\"\n",
    "query_job = client.query(delete_query)\n",
    "query_job.result()\n",
    "print(f\"All data cleared from {TABLE} in {DATASET}.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0297f0-f8c7-485a-94db-08623bc30e53",
   "metadata": {},
   "source": [
    "### 1. Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ab0ae26-93a8-4149-927f-3c4fd79a666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\n",
      "DEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/112246414225-compute@developer.gserviceaccount.com/token?scopes=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE OR REPLACE TABLE cs327e_final_project_2023.currency(\n",
      "    curr_code STRING NOT NULL REFERENCES cs327e_final_project_2023.ticketing(curr_code) NOT ENFORCED,\n",
      "    curr_name STRING NOT NULL,\n",
      "    cntry_code STRING NOT NULL REFERENCES cs327e_final_project_2023.reservations(cnt_code) NOT ENFORCED,\n",
      "    cntry_name STRING NOT NULL,\n",
      "    PRIMARY KEY(curr_code) NOT ENFORCED\n",
      ")\n",
      "\n",
      "Created table\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=PROJECT, location=REGION)\n",
    "\n",
    "ddl_currency = '''CREATE OR REPLACE TABLE cs327e_final_project_2023.currency(\n",
    "    curr_code STRING NOT NULL REFERENCES cs327e_final_project_2023.ticketing(curr_code) NOT ENFORCED,\n",
    "    curr_name STRING NOT NULL,\n",
    "    cntry_code STRING NOT NULL REFERENCES cs327e_final_project_2023.reservations(cnt_code) NOT ENFORCED,\n",
    "    cntry_name STRING NOT NULL,\n",
    "    PRIMARY KEY(curr_code) NOT ENFORCED\n",
    ")\n",
    "'''\n",
    "\n",
    "print(ddl_currency)\n",
    "\n",
    "try:\n",
    "    query_job = client.query(ddl_currency)\n",
    "    query_job.result()\n",
    "    print(\"Created table\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while creating currency table:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a38a8-54d9-4474-bff0-07bd6abef1ef",
   "metadata": {},
   "source": [
    "### 2. Insert records into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20a58e6-179c-4c81-afe5-8975b723c386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 records written into currency table\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "client = bigquery.Client(project=PROJECT, location=REGION)\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Function to get random currency codes from the ticketing table\n",
    "ticketing_query = f\"SELECT curr_code FROM cs327e_final_project_2023.ticketing\"\n",
    "result = client.query(ticketing_query).result()\n",
    "ticketing_codes = [row[\"curr_code\"] for row in result]\n",
    "def get_random_ticketing_code():\n",
    "    return random.choice(ticketing_codes)\n",
    "\n",
    "# Function to get random country codes from the reservations table\n",
    "reservations_query = f\"SELECT cnt_code FROM cs327e_final_project_2023.reservations\"\n",
    "result = client.query(reservations_query).result()\n",
    "reservations_codes = [row[\"cnt_code\"] for row in result]\n",
    "def get_random_reservations_code():\n",
    "    return random.choice(reservations_codes)\n",
    "\n",
    "currency_records = []\n",
    "for _ in range(30):\n",
    "    currency_record = (\n",
    "        get_random_ticketing_code(),\n",
    "        fake.currency_name(),\n",
    "        get_random_reservations_code(),\n",
    "        fake.country(),\n",
    "    )\n",
    "    currency_records.append(currency_record)\n",
    "\n",
    "# Create a list of formatted value strings to insert later\n",
    "formatted_values = [\n",
    "    f'(\"{record[0]}\", \"{record[1]}\", \"{record[2]}\", \"{record[3]}\")' \n",
    "    for record in currency_records\n",
    "]\n",
    "\n",
    "# SQL query\n",
    "sql = f'''INSERT INTO cs327e_final_project_2023.currency(curr_code, curr_name, cntry_code, cntry_name) \n",
    "VALUES {','.join(formatted_values)}'''\n",
    "\n",
    "try:\n",
    "    query_job = client.query(sql)\n",
    "    query_job.result()\n",
    "    print(\"30 records written into currency table\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while writing to table:\", e)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
